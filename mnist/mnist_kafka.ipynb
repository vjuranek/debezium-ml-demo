{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45135531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "BATCH_SIZE=64\n",
    "MAX_EPOCHS=5\n",
    "NUM_COLUMNS=784\n",
    "\n",
    "KAFKA_SERVERS=\"kafka:9092\"\n",
    "KAFKA_CONSUMER_GROUP=\"mnistcg\"\n",
    "KAFKA_TRAIN_TOPIC=\"tf.public.mnist_train\"\n",
    "KAFKA_TEST_TOPIC=\"tf.public.mnist_test\"\n",
    "KAFKA_STREAM_TIMEOUT=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_kafka_record(record):\n",
    "    img_int = tf.io.decode_csv(record.message, [[0.0] for i in range(NUM_COLUMNS)])\n",
    "    img_norm = tf.cast(img_int, tf.float32) / 255.\n",
    "    label_int = tf.strings.to_number(record.key, out_type=tf.dtypes.int32)\n",
    "    return (img_norm, label_int)\n",
    "\n",
    "train_ds = tfio.IODataset.from_kafka(KAFKA_TRAIN_TOPIC, partition=0, offset=0, servers=KAFKA_SERVERS)\n",
    "train_ds = train_ds.map(decode_kafka_record)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7718b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(NUM_COLUMNS,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(train_ds,epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_kafka_stream_record(message, key):\n",
    "    img_int = tf.io.decode_csv(message, [[0.0] for i in range(NUM_COLUMNS)])\n",
    "    img_norm = tf.cast(img_int, tf.float32) / 255.\n",
    "    label_int = tf.strings.to_number(key, out_type=tf.dtypes.int32)\n",
    "    return (img_norm, label_int)\n",
    "\n",
    "test_ds = tfio.experimental.streaming.KafkaGroupIODataset(\n",
    "    topics=[KAFKA_TEST_TOPIC],\n",
    "    group_id=KAFKA_CONSUMER_GROUP,\n",
    "    servers=KAFKA_SERVERS,\n",
    "    stream_timeout=KAFKA_STREAM_TIMEOUT,\n",
    "    configuration=[\n",
    "        \"session.timeout.ms=10000\",\n",
    "        \"max.poll.interval.ms=10000\",\n",
    "        \"auto.offset.reset=earliest\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(decode_kafka_stream_record)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "\n",
    "res = model.evaluate(test_ds)\n",
    "print(\"test loss, test acc:\", res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
